{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1fa94fd-36bc-4a91-9713-ca3efcb94521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cde0b9da-c765-4263-8e9f-525c222aebc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c21b95a8-6785-4a81-a100-10cb176efe4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] The system cannot find the file specified: 'lame_horse'\n",
      "C:\\Users\\pham\\lame_horse\n"
     ]
    }
   ],
   "source": [
    "%cd lame_horse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cc61008-7810-4381-95c3-b2c8ec32429b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "The path 'lame horse/dataset/test/4.mp4' does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlame horse/dataset/test/4.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(video_path):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe path \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: The path 'lame horse/dataset/test/4.mp4' does not exist."
     ]
    }
   ],
   "source": [
    "video_path = 'lame horse/dataset/test/4.mp4'\n",
    "if not os.path.exists(video_path):\n",
    "    raise FileNotFoundError(f\"The path '{video_path}' does not exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc80b9f7-b999-4d9b-a17d-b14968ee670f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is System\n",
      " Volume Serial Number is 56BE-7538\n",
      "\n",
      " Directory of C:\\Users\\pham\\lame horse\\dataset\\test\\lame\n",
      "\n",
      "04/07/2024  13:17    <DIR>          .\n",
      "04/07/2024  13:17    <DIR>          ..\n",
      "04/07/2024  13:17    <DIR>          .ipynb_checkpoints\n",
      "22/06/2024  14:31         9,930,787 4.mp4\n",
      "               1 File(s)      9,930,787 bytes\n",
      "               3 Dir(s)  386,411,016,192 bytes free\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5863ab41-3ae9-4a75-9fc9-bf9adc601c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Unable to open output video file\n",
      "Processig finished!\n"
     ]
    }
   ],
   "source": [
    "# Define the GetKps class for keypoint extraction\n",
    "class GetKps:\n",
    "    def __init__(self, model_path):\n",
    "        self.model = YOLO(model_path).to(device_name)\n",
    "        \n",
    "\n",
    "    def extractkps(self, frame):\n",
    "        results = self.model(frame)\n",
    "        kps_list = []\n",
    "\n",
    "        if results:\n",
    "            for r in results:\n",
    "                if hasattr(r, 'keypoints'):\n",
    "                    keypoints = r.keypoints.xyn.cpu().numpy()\n",
    "                    kps_list.append(keypoints)\n",
    "                else:\n",
    "                    print(\"No keypoints attribute found in the results.\")\n",
    "                    kps_list.append(self._get_dummy_keypoints(frame.shape))\n",
    "        else:\n",
    "            print(\"No results found.\")\n",
    "            kps_list.append(self._get_dummy_keypoints(frame.shape))\n",
    "        return kps_list\n",
    "\n",
    "    def _get_dummy_keypoints(self, shape):\n",
    "        return np.zeros((17, 3))\n",
    "\n",
    "# Define the PositionalEncoding class for the transformer\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=1000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.encoding = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        self.encoding[:, 0::2] = torch.sin(position * div_term)\n",
    "        self.encoding[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.encoding = self.encoding.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoding[:, :x.size(1), :].to(x.device)\n",
    "\n",
    "# Define the 3D Conv network (if not pre-trained)\n",
    "class Conv3D_2L(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Conv3D_2L, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv3d(3, 16, kernel_size=(3, 3, 3), padding=(1, 1, 1)),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2)),\n",
    "            nn.Conv3d(16, 32, kernel_size=(3, 3, 3), padding=(1, 1, 1)),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2)),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return x\n",
    "\n",
    "# Define the HorseLamenessClassifier class\n",
    "class HorseLamenessClassifier(nn.Module):\n",
    "    def __init__(self, feature_model, d_model, nhead, num_layers):\n",
    "        super(HorseLamenessClassifier, self).__init__()\n",
    "        self.feature_model = feature_model\n",
    "        self.positional_encoding = PositionalEncoding(d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.classifier = nn.Linear(d_model, 2)  # 2 classes: lame or sound\n",
    "\n",
    "    def forward(self, video_frames, keypoints=None):\n",
    "        video_features = self.feature_model(video_frames)\n",
    "        if keypoints is not None and len(keypoints) > 0:\n",
    "            keypoints = np.array(keypoints)\n",
    "            keypoints = torch.from_numpy(keypoints).float().to(device_name)\n",
    "            combined_features = torch.cat((video_features, keypoints), dim=1)\n",
    "        else:\n",
    "            combined_features = video_features\n",
    "\n",
    "        # Positional Encoding\n",
    "        combined_features = self.positional_encoding(combined_features)\n",
    "\n",
    "        # Transformer Encoder\n",
    "        encoded_features = self.transformer_encoder(combined_features)\n",
    "        encoded_features = encoded_features.mean(dim=1)  # global average pooling over the sequence\n",
    "\n",
    "        # Classification\n",
    "        logits = self.classifier(encoded_features)\n",
    "        return logits\n",
    "\n",
    "# Load YOLO model\n",
    "model_path = 'best.pt'\n",
    "yolo_model = GetKps(model_path)\n",
    "\n",
    "# Load Pretrained Video Feature Extractor\n",
    "model_load_path = 'lame horse'\n",
    "feature_model = torch.load(model_load_path)\n",
    "feature_model.fc = nn.Identity()\n",
    "feature_model = feature_model.to(device_name)\n",
    "feature_model.eval()\n",
    "\n",
    "# Initialize the HorseLamenessClassifier model\n",
    "model = HorseLamenessClassifier(feature_model=feature_model, d_model=32, nhead=8, num_layers=4)\n",
    "model.to(device_name)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Video processing\n",
    "video_path = 'dataset/test/4.mp4'\n",
    "output_path = 'processed_video_transformer.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "if not out.isOpened():\n",
    "    print('Error: Unable to open output video file')\n",
    "else:\n",
    "    print(f\"Output video file opened, width: {width}, height: {height}, fps: {fps}\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Extract keypoints\n",
    "    try: \n",
    "        keypoints = yolo_model.extractkps(frame)\n",
    "        keypoints = results[0].keypoints.xy.cpu().numpy() if  hasattr(results[0], 'keypoints') else yolo_model._get_dummy_keypoints(frame.shape)\n",
    "    except Exception as e:  # Catch any potential errors during keypoint detection\n",
    "        print(f\"Error detecting keypoints: {e}\")\n",
    "        keypoints = yolo_model._get_dummy_keypoints(frame.shape)\n",
    "        \n",
    "    # Preprocess frame and get video features\n",
    "    processed_frame = preprocess_frame(frame)\n",
    "    with torch.no_grad():\n",
    "        video_features = feature_model(processed_frame.unsqueeze(0).to(device_name))\n",
    "\n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        output = model(video_features, keypoints)  # Get logits\n",
    "        _, predicted = torch.max(output, dim=1)  # Get class prediction\n",
    "\n",
    "    # Draw bounding box and keypoints\n",
    "    results = yolo_model.model(frame)\n",
    "    for result in results:\n",
    "        if hasattr(result, 'boxes'):\n",
    "            boxes = result.boxes.xyxy.cpu().numpy().astype(int)\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = box\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    if keypoints is not None and keypoints.size > 0:\n",
    "        for kp in keypoints[0]:\n",
    "            x, y, _ = kp\n",
    "            cv2.circle(frame, (int(x * width), int(y * height)), 3, (0, 0, 255), -1)\n",
    "\n",
    "    # Display Label\n",
    "    label = \"Lame\" if predicted.item() == 0 else \"Sound\"\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    text_size = cv2.getTextSize(label, font, 1, 2)[0]\n",
    "    text_x = int((frame.shape[1] - text_size[0]) / 2)\n",
    "    text_y = int((frame.shape[0] + text_size[1]) / 2)\n",
    "    cv2.putText(frame, label, (text_x, text_y), font, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "   \n",
    "    out.write(frame)  # Write the frame to the output video\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print('Processig finished!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e346088-6087-4bf5-9e90-7687083acd1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
